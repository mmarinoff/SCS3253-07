# -*- coding: utf-8 -*-
"""PROJECT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/116Lkr8wDqI7rnJ_zBQmAVONdkVnL38Hu
"""

from google.colab import drive
drive.mount('/content/gdrive')
import pandas as pd

path = '/gdrive/My Drive/train.csv'

from google.colab import files
import pandas as pd
uploaded = files.upload()

df=pd.read_csv("train.csv")

df.info

df.describe

#define target and predictors
y = df['target']
X = df.drop(['target', 'ID_code'], axis=1)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1364, stratify=y)
print(f"X_train.shape: {X_train.shape}")
print(f"X_test.shape: {X_test.shape}")
print(f"y_train.shape: {y_train.shape}")
print(f"y_test.shape: {y_test.shape}")

#define the Plots for Checking the roc_auc values vs Parameter

def plot_Parameters_Vs_Scores(criterion_estimators,roc_auc_values,plotType):
    if plotType == "Scatter":
        plt.scatter(criterion_estimators, roc_auc_values)
    if plotType == "Line":
        plt.plot(criterion_estimators, roc_auc_values) 
    plt.xlabel("Parameters Vs AUC Scores")
    plt.legend(loc="best")
    plt.grid(True)

#Evaluate the Decision tree model on the training set
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import roc_auc_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

criterion_estimators_1 = ['gini', 'entropy']

#Establish the first Parameter.
roc_auc_values = []

for item in criterion_estimators_1:
    Dtree_clf = DecisionTreeClassifier(criterion=item, random_state=42)
    Dtree_clf.fit(X_train, y_train)

    y_probas_trees = cross_val_predict(Dtree_clf,X_train,y_train, cv=4, method="predict_proba")
    y_tree_scores = y_probas_trees[:, 1] # score = proba of positive class
    roc_auc_trees = roc_auc_score(y_train,y_tree_scores)
    roc_auc_values.append(roc_auc_trees)

plot_Parameters_Vs_Scores(criterion_estimators_1, roc_auc_values,"Line")
plt.show()

import matplotlib.pyplot as plt

#import the libraries for all the classifiers.

from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split

from sklearn.model_selection import StratifiedShuffleSplit

X_train, X_nontrain, y_train, y_nontrain = train_test_split(X, y, test_size=0.25, random_state=10086, stratify=y) #stratified sampling based on the target
print(f"X_train.shape: {X_train.shape}")
print(f"X_nontrain.shape: {X_nontrain.shape}")
print(f"y_train.shape: {y_train.shape}")
print(f"y_nontrain.shape: {y_nontrain.shape}")

X_stack, X_test, y_stack, y_test = train_test_split(X_nontrain, y_nontrain, test_size=0.25, random_state=10086, stratify=y_nontrain) #stratified sampling based on the target
print(f"X_stack.shape: {X_stack.shape}")
print(f"X_test.shape: {X_test.shape}")
print(f"y_stack.shape: {y_stack.shape}")
print(f"y_test.shape: {y_test.shape}")

#Design the random forest classifier

# Random Forest Classifier

n_estimators = [10, 200]
max_features = [0.1, 0.5]
max_depth = [2, 10, 20] 
oob_score = [True, False]
min_samples_split = [0.1, 0.5]
min_samples_leaf = [0.1, 0.5]
max_leaf_nodes = [2, 10, 100]

parameter_random_forest = {'n_estimators' : n_estimators, 'max_features' : max_features,
                     'max_depth' : max_depth, 'min_samples_split' : min_samples_split,
                    'oob_score' : oob_score, 'min_samples_leaf': min_samples_leaf, 
                     'max_leaf_nodes' : max_leaf_nodes}
             
Random_Forest_Classifier = RandomForestClassifier(random_state = 42)

#use grid search to tune the model

grid_search_RndmForest = GridSearchCV(Random_Forest_Classifier,parameter_random_forest, cv = 4, scoring='roc_auc', refit = True,
                                     n_jobs = -1, verbose=2)

grid_search_RndmForest.fit(X_train,y_train)
             
forest_best_params_ = grid_search_RndmForest.best_params_
forest_best_estimators_ = grid_search_RndmForest.best_estimator_

print(forest_best_params_)
print(forest_best_estimators_)

